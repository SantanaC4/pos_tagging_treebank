{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pos_tagging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAEOKNugqsLywRBbaSnkXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantanaC4/pos_tagging_treebank/blob/main/pos_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRCz6LkodLTU"
      },
      "source": [
        "# Implementation Part of Speech Tagging from Treebank corpus using N-gram tecnique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVOeKgeJdRRz"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSCQ7rCLXJKU"
      },
      "source": [
        "## Some functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBP-wp0Ivbb2"
      },
      "source": [
        "##Upload Penn Treebank Corpus\n",
        "# That function filter the pair (word, tag) of the data\n",
        "\n",
        "def pair_filter(section):\n",
        "  if (section == \"training\"):\n",
        "    url = 'https://raw.githubusercontent.com/SantanaC4/pos_tagging_treebank/main/Sec0-18_training'\n",
        "  if (section == \"development\"):\n",
        "    url = 'https://raw.githubusercontent.com/SantanaC4/pos_tagging_treebank/main/Sec-19-21_development'\n",
        "  if (section == \"testing\"):\n",
        "    url = 'https://raw.githubusercontent.com/SantanaC4/pos_tagging_treebank/main/Sec-22-24_testing'\n",
        "\n",
        "  df = pd.read_csv(url, header=None, sep='\\n')\n",
        "  spliting =  [i.split(\" \") for i in df[0]]\n",
        "  extracting_pair = []\n",
        "\n",
        "  count = 0\n",
        "  for i in spliting:\n",
        "    if (len(i) == 1):\n",
        "      if (i[0] != \"''_''\"):\n",
        "          extracting_pair.append(tuple(i[0].split(\"_\")))\n",
        "    else:\n",
        "      for j in i:\n",
        "        if (j != \"''_''\" and j != \"'_''\"):\n",
        "          extracting_pair.append(tuple(j.split(\"_\")))\n",
        "  return (extracting_pair)\n",
        "\n",
        "## Function to sort tags probability\n",
        "def sort_tags_probability(tags_frequency, word_frequency):\n",
        "    result = []\n",
        "    for (key, value) in tags_frequency.items():\n",
        "      result.append((round(value/word_frequency, 2), key))\n",
        "    return (sorted(result, reverse=True))\n",
        "\n",
        "## Function to evaluating bigram model\n",
        "def evaluating_bigram(model):\n",
        "  tt = pair_filter(\"testing\")\n",
        "  aux = \"<s>\"\n",
        "\n",
        "  accuracy = 0\n",
        "  for (word, tag) in tt:\n",
        "    if (model[aux + \" \" + word][0][1] == 'Unknown word'):\n",
        "      if (model[aux + \" \" + '<UNK>'][0][1] == tag):\n",
        "        accuracy += 1\n",
        "    elif (model[aux + \" \" + word][0][1] == tag):\n",
        "      accuracy += 1\n",
        "    aux = tag\n",
        "\n",
        "  return (accuracy/len(tt))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibMnALNgKWNC"
      },
      "source": [
        "##Unigram Tagger \n",
        "####Building a dictionary with probability of tags for each word based on the following equation.\n",
        "\n",
        "$$\n",
        "P(t_i|s_i) = \\frac{C(t_i,s_i)}{C(s_i)}\n",
        "$$\n",
        "####This says that the emission probability of tag i given state i is the total number of times we observe state i emitting tag i divided by the total number of times we observe state i."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U1FixlI3fU1",
        "outputId": "2b4dfb91-5b33-465a-ec8d-1bb78e1fdc77"
      },
      "source": [
        "## Default dictionary \n",
        "## Assign default value to key that is not in dictionary\n",
        "from collections import defaultdict\n",
        "\n",
        "unigram = defaultdict(list)\n",
        "for (word, tag) in pair_filter(\"training\"):\n",
        "  unigram[word].append(tag)\n",
        "\n",
        "########################### This is optional#######################################\n",
        "##########################Treatment for unknown words##############################\n",
        "# Unknown words: replace the words whose frequency is lesser five for <UNK>\n",
        "unigram_with_unk = defaultdict(list)\n",
        "for i in unigram.items():\n",
        "  if (len(i[1]) < 5):\n",
        "    for j in i[1]:\n",
        "      unigram_with_unk['<UNK>'].append(j)\n",
        "  else:\n",
        "    for j in i[1]:\n",
        "      unigram_with_unk[i[0]].append(j)\n",
        "  \n",
        "count_unk_tags = defaultdict(int)\n",
        "for i in unigram_with_unk['<UNK>']:\n",
        "  count_unk_tags[i] += 1\n",
        "\n",
        "max_key = max(count_unk_tags, key=count_unk_tags.get)\n",
        "probability_of_unk_tag = count_unk_tags[max_key] / len(unigram_with_unk['<UNK>'])\n",
        "tags_probability = defaultdict(lambda: [(probability_of_unk_tag ,max_key)])\n",
        "unigram = unigram_with_unk\n",
        "\n",
        "#################################################################################\n",
        "#################################################################################\n",
        "\n",
        "\n",
        "#### Warning ####\n",
        "#### the line below should be uncommented out if the optional part above for commented\n",
        "#### defaultdisct((lambda: [(0, 'NN')]) assign the 'NN' tag for unseend words in testing set\n",
        "#### Warning ####\n",
        "\n",
        "#tags_probability = defaultdict(lambda: [(0, 'NNP')])\n",
        "word_freq = 0\n",
        "aux = defaultdict(int)\n",
        "\n",
        "for (word, tags) in unigram.items():\n",
        "  word_freq = len(tags)\n",
        "  for i in tags:\n",
        "    aux[i] += 1\n",
        "  tags_probability[word] = sorted([(value/word_freq, key) for (key, value) in aux.items()], reverse=True)\n",
        "  aux = defaultdict(int)\n",
        "  word_freq = 0\n",
        "\n",
        "unigram_with_unk = tags_probability\n",
        "\n",
        "\n",
        "print(unigram_with_unk['<UNK>'])\n",
        "# unknown word\n",
        "print(unigram_with_unk['asdfasdfasdfasdf'])\n",
        "print(unigram_with_unk['is'])\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0.25982905982905985, 'NNP'), (0.17251043530113297, 'NN'), (0.16189624329159213, 'JJ'), (0.11288014311270125, 'CD'), (0.10383621546412244, 'NNS'), (0.04184058835221626, 'VBG'), (0.031922083084873785, 'VBN'), (0.027807592923871995, 'VB'), (0.021904193997217252, 'RB'), (0.019618366129994038, 'VBD'), (0.01892267938779567, 'VBZ'), (0.009222818525144106, 'NNPS'), (0.0062413039157225205, 'VBP'), (0.0027429934406678594, 'JJR'), (0.0021864440469091632, 'JJS'), (0.0019479228781554363, 'FW'), (0.0015503875968992248, 'IN'), (0.0006758099781355595, 'UH'), (0.00035778175313059033, 'PRP'), (0.00033790498906777975, 'RBR'), (0.0003180282250049692, 'SYM'), (0.000278274696879348, 'WRB'), (0.0002385211687537269, 'MD'), (0.00019876764062810574, 'CC'), (0.00011926058437686345, 'DT'), (9.938382031405287e-05, 'LS'), (7.95070562512423e-05, 'WP'), (7.95070562512423e-05, 'WDT'), (7.95070562512423e-05, 'TO'), (5.9630292188431724e-05, 'RP'), (5.9630292188431724e-05, 'PDT'), (5.9630292188431724e-05, '$'), (3.975352812562115e-05, 'RBS'), (1.9876764062810574e-05, '``'), (1.9876764062810574e-05, 'PRP$'), (1.9876764062810574e-05, ',')]\n",
            "[(0.25982905982905985, 'NNP')]\n",
            "[(0.9997030438010394, 'VBZ'), (0.0002969561989606533, 'NNS')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pw2kbVhK31v",
        "outputId": "02fddc6f-1393-4c7b-80ba-7245210680db"
      },
      "source": [
        "# Evaluating unigram model with <UNK> technique\n",
        "\n",
        "tt = pair_filter(\"testing\")\n",
        "tt[0]\n",
        "accuracy = 0\n",
        "for (word, tag) in tt:\n",
        "    if (tags_probability[word][0][1] == tag):\n",
        "      accuracy += 1\n",
        "\n",
        "accuracy/len(tt)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9001158550334736"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXq14_TC05ju"
      },
      "source": [
        "Accuracy without group up words less frequenty:\n",
        "0.9001158550334736 (92%)\n",
        "\n",
        "Accuracy to '< UNK >' words. 0.9073474478924616 (90%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM6bDQ4uHRe-"
      },
      "source": [
        "##Bigram Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HSvs9vNHQTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5d1e0d-fe97-4011-8427-5e1404ae15fe"
      },
      "source": [
        "###Using the previous word to compute the probability\n",
        "\n",
        "def bigram_model(previous, with_unk=0):\n",
        "  bigram = defaultdict(list)\n",
        "  aux = \"<s>\"\n",
        "\n",
        "  for (word, tag) in pair_filter(\"training\"):\n",
        "      bigram[aux + \" \" + word].append(tag)\n",
        "      if (previous == \"word\"):\n",
        "        aux = word\n",
        "      elif (previous == \"tag\"):\n",
        "        aux = tag\n",
        "  \n",
        "  tags_frequency = defaultdict(int)\n",
        "  result = defaultdict(lambda: [(-1 ,'NNP')])\n",
        "\n",
        "  #\n",
        "  if (with_unk == 1):\n",
        "    aux = \"<s>\"\n",
        "    bigram_with_unk = defaultdict(list)\n",
        "    for i in bigram.items():\n",
        "      if (len(i[1]) < 5):\n",
        "        for j in i[1]:\n",
        "                bigram_with_unk[i[0].split(' ')[0] + \" \" + '<UNK>'].append(j)\n",
        "      else:\n",
        "        for j in i[1]:\n",
        "                bigram_with_unk[i[0]].append(j)\n",
        "\n",
        "    print(\"Quantidade de bigramas sem <UNK>: \", len(bigram.items()))\n",
        "    print(\"Quantidade de bigramas com <UNK>: \", len(bigram_with_unk.items()))\n",
        "\n",
        "    result = defaultdict(lambda: [(0, 'Unknown word')])\n",
        "    bigram = bigram_with_unk\n",
        "  #\n",
        "\n",
        "  for (word, tags) in bigram.items():\n",
        "    for i in tags:\n",
        "      tags_frequency[i] += 1\n",
        "    result[word] = sort_tags_probability(tags_frequency, len(tags))\n",
        "    tags_frequency = defaultdict(int)\n",
        "  return result\n",
        "\n",
        "# Model without <UNK>\n",
        "bigram_without_unk = bigram_model(\"tag\")\n",
        "\n",
        "# Model with <UNK>\n",
        "bigram_with_unk = bigram_model(\"tag\", 1)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de bigramas sem <UNK>:  122034\n",
            "Quantidade de bigramas com <UNK>:  20015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0azgWvs3XuxY",
        "outputId": "71cd4f07-ca3e-4c69-d885-7b3cec80fc6d"
      },
      "source": [
        "## Evaluating\n",
        "\n",
        "print(\"Accuracy of bigram model without <UNK> technique: \", evaluating_bigram(bigram_without_unk))\n",
        "print(\"Accuracy of bigram model with <UNK> technique: \", evaluating_bigram(bigram_with_unk))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of bigram model without <UNK> technique:  0.9067639123233988\n",
            "Accuracy of bigram model with <UNK> technique:  0.8594344097224922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pa5TdcPW-VE"
      },
      "source": [
        "## Trigram Tagger with Backoff smoothing technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTSjZeM2XEbi",
        "outputId": "ed84d771-4e93-4c56-b301-db2ffd7d47e9"
      },
      "source": [
        "def trigram_model(with_unk=0):\n",
        "  trigram = defaultdict(list)\n",
        "  aux = \"<s>\"\n",
        "  aux2 = \"<s>\"\n",
        "\n",
        "  for (word, tag) in pair_filter(\"training\"):\n",
        "      trigram[aux + \" \" + aux2 + \" \" + word].append(tag)\n",
        "      aux = aux2\n",
        "      aux2 = tag\n",
        "\n",
        "  tags_frequency = defaultdict(int)\n",
        "  result = defaultdict(lambda: [(0, \"backoff\")])\n",
        "  for (word, tags) in trigram.items():\n",
        "    for i in tags:\n",
        "      tags_frequency[i] += 1\n",
        "    result[word] = sort_tags_probability(tags_frequency, len(tags))\n",
        "    tags_frequency = defaultdict(int)\n",
        "\n",
        "  trigram = result\n",
        "  return (trigram)\n",
        "\n",
        "trigram = trigram_model(\"tag\")\n",
        "\n",
        "#### Evaluating trigram model with backoff technique\n",
        "aux = \"<s>\"\n",
        "aux2 = \"<s>\"\n",
        "accuracy = 0\n",
        "\n",
        "for (word, tag) in pair_filter(\"testing\"):\n",
        "    if (trigram[aux + \" \" + aux2 + \" \" + word][0][1] == \"backoff\"):\n",
        "        if (bigram_without_unk[aux2 + \" \" + word][0][1] == tag):\n",
        "          accuracy += 1\n",
        "        elif (bigram_without_unk[aux2 + \" \" + word][0][0] == -1):\n",
        "          if (unigram_with_unk[word][0][1] == tag):\n",
        "              accuracy += 1\n",
        "    elif (trigram[aux + \" \" + aux2 + \" \" + word][0][1] == tag):\n",
        "        accuracy += 1\n",
        "    aux = aux2\n",
        "    aux2 = tag\n",
        "\n",
        "print(\"Trigram model accuracy using backoff technique: \", round(accuracy/len(tt)*100, 0),\"%\")\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram model accuracy using backoff technique:  93.0 %\n"
          ]
        }
      ]
    }
  ]
}